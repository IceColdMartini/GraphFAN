{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2deef35",
   "metadata": {},
   "source": [
    "# GFAN Seizure Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ff852",
   "metadata": {},
   "source": [
    "Main execution notebook for the GFAN seizure detection pipeline. This notebook orchestrates data preprocessing, feature extraction, model training, and evaluation using Leave-One-Subject-Out cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f1e47",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b88e80c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mne'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_preprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CHBMITDataProcessor, load_chb_mit_annotations\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspectral_decomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleSTFT\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_construction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_graph_from_windows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GraphFAN/src/data_preprocessing.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmne\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyedflib\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m signal\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mne'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.data_preprocessing import CHBMITDataProcessor, load_chb_mit_annotations\n",
    "from src.spectral_decomposition import MultiScaleSTFT\n",
    "from src.graph_construction import create_graph_from_windows\n",
    "from src.training import EEGDataset, LeaveOneSubjectOutValidator\n",
    "from src.gfan_model import GFAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56905706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mne pyedflib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433c631",
   "metadata": {},
   "source": [
    "### 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data': {\n",
    "        'path': 'chb-mit-scalable-eeg-database-1.0.0',\n",
    "        'target_fs': 256,\n",
    "        'window_size': 2.0,\n",
    "        'overlap': 0.5,\n",
    "        'n_subjects_to_process': 3 # Set to None to process all subjects\n",
    "    },\n",
    "    'features': {\n",
    "        'window_sizes': [1.0, 2.0, 4.0],\n",
    "        'hop_ratio': 0.25,\n",
    "        'log_transform': True\n",
    "    },\n",
    "    'graph': {\n",
    "        'method': 'hybrid',\n",
    "        'spatial_weight': 0.5,\n",
    "        'functional_weight': 0.5\n",
    "    },\n",
    "    'model': {\n",
    "        'n_channels': 18, # Will be updated based on data\n",
    "        'spectral_features_dims': [129, 257, 513], # Will be updated\n",
    "        'hidden_dims': [128, 64],\n",
    "        'n_classes': 2,\n",
    "        'sparsity_reg': 0.01,\n",
    "        'dropout_rate': 0.2,\n",
    "        'uncertainty_method': 'mc_dropout',\n",
    "        'fusion_method': 'attention'\n",
    "    },\n",
    "    'trainer': {\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        'class_weights': [1.0, 10.0], # Will be updated based on data\n",
    "        'sparsity_weight': 0.01,\n",
    "        'kl_weight': 1e-6,\n",
    "        'epochs': 50\n",
    "    },\n",
    "    'validation': {\n",
    "        'n_folds': 3 # Set to None for full LOSO validation\n",
    "    },\n",
    "    'results_path': 'results/final_run_summary.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5b3ff",
   "metadata": {},
   "source": [
    "### 3. Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Metal (MPS) for acceleration.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available. Using CPU.\")\n",
    "config['trainer']['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f54713",
   "metadata": {},
   "source": [
    "### 4. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a91814",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CHBMITDataProcessor(\n",
    "    target_fs=config['data']['target_fs'],\n",
    "    window_size=config['data']['window_size'],\n",
    "    overlap=config['data']['overlap']\n",
    ")\n",
    "stft_extractor = MultiScaleSTFT(\n",
    "    fs=config['data']['target_fs'],\n",
    "    window_sizes=config['features']['window_sizes'],\n",
    "    hop_ratio=config['features']['hop_ratio']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8c1cc",
   "metadata": {},
   "source": [
    "### 5. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a98bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_windows, all_labels, all_subjects = [], [], []\n",
    "all_spectral_features = [[] for _ in config['features']['window_sizes']]\n",
    "\n",
    "subject_dirs = sorted([d for d in glob.glob(os.path.join(config['data']['path'], 'chb*')) if os.path.isdir(d)])\n",
    "if config['data']['n_subjects_to_process'] is not None:\n",
    "    subject_dirs = subject_dirs[:config['data']['n_subjects_to_process']]\n",
    "\n",
    "print(f\"Starting data processing for {len(subject_dirs)} subjects...\")\n",
    "for subject_dir in tqdm(subject_dirs, desc=\"Processing Subjects\"):\n",
    "    subject_id = int(os.path.basename(subject_dir).replace('chb', ''))\n",
    "    summary_file = os.path.join(subject_dir, f\"{os.path.basename(subject_dir)}-summary.txt\")\n",
    "    annotations = load_chb_mit_annotations(summary_file)\n",
    "    \n",
    "    edf_files = sorted(glob.glob(os.path.join(subject_dir, '*.edf')))\n",
    "    \n",
    "    for edf_file in edf_files:\n",
    "        file_name = os.path.basename(edf_file)\n",
    "        seizure_info = annotations.get(file_name, [])\n",
    "        \n",
    "        try:\n",
    "            windows, labels, channels = processor.process_file(edf_file, seizure_info)\n",
    "            if windows is None or len(windows) == 0:\n",
    "                continue\n",
    "\n",
    "            # Extract spectral features for all windows of the file\n",
    "            file_spectral_features = [[] for _ in config['features']['window_sizes']]\n",
    "            for i in range(windows.shape[0]):\n",
    "                multiscale_stft = stft_extractor.compute_multiscale_stft(windows[i])\n",
    "                for scale_idx, stft_result in enumerate(multiscale_stft):\n",
    "                    file_spectral_features[scale_idx].append(stft_result['magnitude'])\n",
    "\n",
    "            all_windows.append(windows)\n",
    "            all_labels.append(labels)\n",
    "            all_subjects.extend([subject_id] * len(windows))\n",
    "            for scale_idx in range(len(all_spectral_features)):\n",
    "                all_spectral_features[scale_idx].append(np.array(file_spectral_features[scale_idx]))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process file {edf_file}. Error: {e}\")\n",
    "\n",
    "# Concatenate all data\n",
    "final_windows = np.concatenate(all_windows, axis=0)\n",
    "final_labels = np.concatenate(all_labels, axis=0)\n",
    "final_subjects = np.array(all_subjects)\n",
    "final_spectral_features = [np.concatenate(scale_features, axis=0) for scale_features in all_spectral_features]\n",
    "\n",
    "print(f\"Total windows processed: {len(final_windows)}\")\n",
    "print(f\"Class distribution: {pd.Series(final_labels).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f42280",
   "metadata": {},
   "source": [
    "### 6. Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Constructing graph...\")\n",
    "graph_info = create_graph_from_windows(\n",
    "    final_windows, \n",
    "    channels, \n",
    "    method=config['graph']['method']\n",
    ")\n",
    "# Move graph tensors to the correct device\n",
    "for key in ['adjacency', 'laplacian', 'eigenvalues', 'eigenvectors']:\n",
    "    graph_info[key] = graph_info[key].to(device)\n",
    "print(\"Graph constructed and moved to device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb2251",
   "metadata": {},
   "source": [
    "### 7. Update Config and Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['model']['n_channels'] = final_windows.shape[1]\n",
    "config['model']['spectral_features_dims'] = [f.shape[1] for f in final_spectral_features]\n",
    "\n",
    "# Update class weights based on data imbalance\n",
    "class_counts = pd.Series(final_labels).value_counts()\n",
    "if 1 in class_counts and 0 in class_counts:\n",
    "    weight_for_class_0 = len(final_labels) / (2 * class_counts[0])\n",
    "    weight_for_class_1 = len(final_labels) / (2 * class_counts[1])\n",
    "    config['trainer']['class_weights'] = [weight_for_class_0, weight_for_class_1]\n",
    "else:\n",
    "    # Handle case where one class is missing in the processed subset\n",
    "    config['trainer']['class_weights'] = [1.0, 1.0]\n",
    "\n",
    "print(f\"Calculated class weights: {config['trainer']['class_weights']}\")\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = EEGDataset(\n",
    "    windows=final_windows,\n",
    "    labels=final_labels,\n",
    "    spectral_features=final_spectral_features,\n",
    "    subjects=final_subjects,\n",
    "    training=False # Augmentation is handled inside the trainer/validator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741187d",
   "metadata": {},
   "source": [
    "### 8. Run Leave-One-Subject-Out Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Leave-One-Subject-Out cross-validation...\")\n",
    "validator = LeaveOneSubjectOutValidator(\n",
    "    model_config=config['model'],\n",
    "    trainer_config=config['trainer']\n",
    ")\n",
    "\n",
    "results = validator.validate(\n",
    "    dataset=full_dataset,\n",
    "    graph_info=graph_info,\n",
    "    n_folds=config['validation']['n_folds']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262eccaa",
   "metadata": {},
   "source": [
    "### 9. Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation finished. Saving results...\")\n",
    "os.makedirs(os.path.dirname(config['results_path']), exist_ok=True)\n",
    "validator.save_results(config['results_path'])\n",
    "\n",
    "print(f\"Results saved to {config['results_path']}\")\n",
    "print(\"\\n--- Summary Metrics ---\")\n",
    "summary = validator.get_summary_metrics()\n",
    "if summary:\n",
    "    for key, value in summary.items():\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
